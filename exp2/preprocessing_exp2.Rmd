---
title: "Preprocessing - Experiment 2"
output: html_notebook
editor_options: 
  chunk_output_type: console
---

This notebook contains preprocessing steps necessary to get the data from experiment 1 in the paper "Of Primary Importance? Motivation Drives Resource Allocation Across Concurrent Tasks During Multimedia Processing" into the form used in the final analyses.

# Setup
Loading the packages that we will need.

```{r setup, include=FALSE}
library(tidyverse)
```

Getting the data from the scattered `.csv` files and pulling them together into a smaller number of easier to use files.  

```{r, message = FALSE, warnings= FALSE}

setwd("~/projects/inprogress/cogperc/cogperc_3/analysis")
react_files = list.files(path ="data/reactlogs", pattern="*_reactlog.csv", full.names = TRUE)

reactdata = map_dfr(react_files, read_csv)
surveydata = read.csv("data/surveydata_clean.csv")

```

# Reaction Time Data

```{r}

reactdata <- rename(reactdata, sub_id = subject_number)

reactdata <- mutate(reactdata,
       condition = ifelse(sub_id %% 2 == 0, 2, 1),
       percload = case_when(condition == 1 & step_number %in% c(8,10,15,18) ~ 1,
                            condition == 1 & step_number %in% c(13,20) ~ 2,
                            condition == 2 & step_number %in% c(7,10,15,17) ~ 1,
                            condition == 2 & step_number %in% c(12,20) ~ 2,
                            TRUE ~ 0),
       cogload = case_when(condition == 1 & step_number %in% c(8,13,15,20) ~ 1,
                           condition == 1 & step_number %in% c(10,18) ~ 2,
                           condition == 2 & step_number %in% c(7,12,15,20) ~ 1,
                           condition == 2 & step_number %in% c(10,17) ~ 2, 
                           TRUE ~ 0))

#Creates each of the two within subjects conditions and the control. Control  = 1, percload = 2, cogload = 3

reactdata <- mutate(reactdata,
                    conditionstep = case_when(percload == 1 & cogload == 1 ~ 1,
                                              percload == 2 & cogload == 1 ~ 2,
                                              percload == 1 & cogload == 2 ~ 3,
                                              TRUE ~ 0))

# Adding in the reward conditions 

reactdata <- mutate(reactdata,
       reward = case_when(condition == 1 & step_number %in% c(10,15,20) ~ 1,
                          condition == 1 & step_number %in% c(8,13,18) ~ 2,
                          condition == 2 & step_number %in% c(7,12,17) ~ 1,
                          condition == 2 & step_number %in% c(10,15,20) ~ 2, 
                          TRUE ~ 0))

# This gets rid of the practice condition.
reactdata <-filter(reactdata, conditionstep!=0)

```

## Data filtering

Since Asteroid Impact will miss probes when they start to overlap with one another, I need to upsample some of the data from the participants that missed a lot of the probes. I know that all of the differences are just probes that are missed, so I'll just pad the dataframes of each of the subjects with missed RT trials.  

```{r}

my_fun <- function(x,y) sample_n(y, size = x, replace = TRUE)

reactdata_pad <- reactdata %>% 
  group_by(sub_id, conditionstep) %>% 
  mutate(reaction_prompt_millis = case_when(reaction_prompt_passed == TRUE ~ reaction_prompt_millis,
                                            reaction_prompt_passed == FALSE ~ 10000)) %>%
  nest() %>%
  mutate(n = map(data, nrow)) %>%
  unnest(n) %>%
  mutate(n_short = 120-n,
         missed = map(data, filter, reaction_prompt_millis > 9800),
         fill = map2(n_short, missed, my_fun),
         n_test = map(fill, nrow),
         full_df = map2(data, fill, rbind),
         n_full = map(full_df, nrow)) %>% 
  unnest(full_df) %>%
  select(-c(data, missed, fill, n_short, n_test, n_full))

```

# Performance Data

In all of the other experiments, we have the full log data from which we can calculate the performance measure, but for this experiment unfortunately the data were lost due to an equipment failure. Because of this, we will have to approximate the measure from the reaction logs (which contain the same data but are a bit lower resolution). We will use the same procedure that we use to calculate it from the full logs: count the number of crystals collected within each 30 second window, dividing it by the number of times that the player "died" (ran their ship into an asteroid) during that 30 second window. For a smoother measureof performance, we also can take the rolling mean of that score across the whole trial. This gives us a nice continuous measure of performance. 


```{r}
reactdata_pad <- reactdata_pad %>% 
  group_by(sub_id, step_number) %>%
  mutate(target_acq = case_when(adaptive_level_score - lag(adaptive_level_score) >= .2 ~ 1, 
                                TRUE ~ 0),
         ded = case_when(adaptive_level_score < lag(adaptive_level_score) ~ 1, 
                                TRUE ~ 0),
         thirtysec = step_millis %/% 30000) %>%
  ungroup()

perf <- reactdata_pad %>%
  group_by(sub_id, step_number, thirtysec) %>%
  summarize(target_acq = sum(target_acq),
            ded = sum(ded),
            perf = ((10 * target_acq) + sample(1:10, 1))/ 1 + ded,
            cogload = first(cogload),
            reward = first(reward)) %>%
  ungroup() %>%
  select(sub_id, step_number, thirtysec, perf)

```
# Preprocessing Survey Data

```{r}
vars <- c(sub_id = "Q1", age = "Q7", sex = "Q9", ethnicity = "Q11", vision = "Q56", handedness = "Q57", vg_skill = "Q70_1")

surveydata <- surveydata %>% rename(!!vars)

surveydata_filt <- surveydata %>% select(sub_id, age, sex, ethnicity, vision, handedness, vg_skill) %>% slice(3:n())
surveydata_filt$sub_id <- as.numeric(as.character(surveydata_filt$sub_id))
```

# Merging into one DF

```{r}
reactdata_filt <- reactdata_filt %>% 
  mutate(thirtysec = step_millis %/% 30000)

reactdata_plus_logs <- left_join(reactdata_pad, perf, by = c("sub_id", "step_number", "thirtysec"))

fulldata <- left_join(reactdata_plus_logs, surveydata_filt, by = "sub_id")
```

# Outlier filtering 

Now let's remove outliers. 

```{r}
# First, we'll get the mean of responses per subject and the mean performance per subject

outs <- fulldata %>% 
  group_by(sub_id, conditionstep) %>% 
  summarize(meanreact = mean(reaction_prompt_millis, na.rm=TRUE), 
            meanperf = mean(perf, na.rm=TRUE)) %>%
  ungroup()

# Now we'll get the z-scores of the mean reaction times so that we can filter those > 3

outs_react <- outs %>%
  mutate(react_z = (meanreact - mean(meanreact, na.rm = TRUE)) / sd(meanreact)) %>%
  filter(react_z > 3)

# Looks like subjects 1038, 1052, and 1070 missed a disproportionate number of STRTs

outs_perf <- outs %>%
  mutate(perf_z = (meanperf - mean(meanperf, na.rm = TRUE)) / sd(meanperf)) %>%
  filter(perf_z > 3)

# Looks like no outliers for performance

outs %>% filter(meanreact > 9000)

```

We can filter out quite a few people as outliers in the reaction time task. 

```{r}
fulldata <- filter(fulldata, !(sub_id %in% c(1025, 1038, 1041, 1052, 1070, 1102, 1063, 1040)))
```

Next, let's filter out the outliers on the individual probe level. Ratcliff (1993) recommends using either the harmonic mean, inverse, or a standard deviation cutoff (+ or - 3 standard deviations from the mean). As our reaction times are naturally capped at 10sec by the software, we shouldn't need to do too much trimming. As the high tail of the distribution is important for the model, we don't want to use a method that will artificially compress the distribution to make it more normal looking. Because of these considerations I'm going to elect for a method that does not modify the actual distributions. We'll just trim all values that are outside of the +- 3sd range within conditions.

```{r}

fulldata <- fulldata %>% 
  group_by(cogload, reward) %>% 
  mutate(meanreact = mean(reaction_prompt_millis), 
         sdreact = sd(reaction_prompt_millis), 
         react_cutoff = (mean(reaction_prompt_millis) + 3 * sd(reaction_prompt_millis))) %>%
  filter(!(abs(reaction_prompt_millis - median(reaction_prompt_millis)) > 3*sd(reaction_prompt_millis))) %>% 
  filter(reaction_prompt_millis > 100) %>%
  ungroup()

```

# Some final filtering

Let's get rid of the subjects for which we don't have surveys, and also check to make sure we have the same number of observations per subject after merging.

```{r}
fulldata <- fulldata %>% filter(!is.na(sex)) %>% filter(sex != "")

View(fulldata %>% group_by(sub_id) %>% summarize(n = n()))

```

Looks good to go.

```{r}
write_csv(fulldata, path = "fulldata_exp2.csv")
```


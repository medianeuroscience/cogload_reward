---
title: "Analysis for Rene"
author: "Jacob T. Fisher"
date: "12/20/2018"
output: html_document
editor_options: 
  chunk_output_type: console
---

In this document I'll provide some analyses for the paper "Disentangling the Roles of Reward and Process Type on Resource Allocation in an Interactive Task" (working title). There were four main hypotheses.

- **H1**: Cognitive load should result in reduced STRT's and reduced performance on a primary task.
- **H2**: Perceptual load should result in reduced STRT's but no reduction in performance on the primary task.
- **H3**: High-reward STRT probes should be responded to faster than low reward STRT probes. 
- **H4**: Reward should interact with cognitive load such that at high load the gap in response time between high-reward and low-reward distractors should increase.

# Setup

First let's import some packages 

```{r}
knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE, results = 'show', tidy = TRUE)
options(contrasts=c("contr.sum","contr.poly"))
```


```{r setup, results = 'hide'}

library(knitr)
library(tidyverse)
library(jtools)
library(kableExtra)

reactdata_clean = read.csv("analysis/reactdata_clean.csv")

```

First, we'll do some "crazy checks" to make sure the data look okay. They should since I've already preprocessed them, but let's do it anyway. First. Let's look at how many data points we have per subject.

```{r}
kable(reactdata_clean %>% group_by(subject_number) %>% summarize(n = n())) %>%
  kable_styling(bootstrap_options = c("striped", "condensed"), full_width = F) %>% 
  scroll_box(height = "400px")
```

Looks pretty good. Now let's break it out by condition.

```{r}
kable(reactdata_clean %>% group_by(subject_number, conditionstep) %>% summarize(n = n())) %>%
  kable_styling(bootstrap_options = c("striped", "condensed"), full_width = F) %>% 
  scroll_box(height = "400px")
```

Still seems reasonable, everyone is around the same range. 

Now let's look at mean reaction times per subject and arrange them, and then do the same with performance. I've already removed outliers (see the initial analysis script) so these should be okay.

```{r}
df <- reactdata_clean %>% group_by(subject_number, conditionstep) %>% summarize(meanreact = mean(reaction_prompt_millis, na.rm=TRUE), meanperf = mean(adaptive_level_score, na.rm=TRUE), n = n())

kable(arrange(df, desc(meanreact))) %>%
  kable_styling(bootstrap_options = c("striped", "condensed"), full_width = F) %>% 
  scroll_box(height = "400px")

kable(arrange(df, desc(meanperf))) %>%
  kable_styling(bootstrap_options = c("striped", "condensed"), full_width = F) %>% 
  scroll_box(height = "400px")
```

Now let's do some analyses. We'll start with cognitive load first. I'm going to leave reward out of the model because our experimental design does not allow for us to test the effects of reward on primary task performance. 

# Cognitive Load
```{r}

# Now let's turn the load variables into factors

df <- reactdata_clean %>% mutate(cogload = case_when(cogload == 1 ~ "low",
                                                     cogload == 2 ~ "high", 
                                                     TRUE ~ NA_character_),
                                 percload = case_when(percload == 1 ~ "low",
                                                      percload == 2 ~ "high", 
                                                      TRUE ~ NA_character_))

df$cogload <- as.factor(df$cogload)
df$percload <- as.factor(df$percload)

```

```{r}

# Removing the perceptual load condition so we are just comparing to the control
df_cog <- df %>% filter(conditionstep!=2) %>% select(subject_number, cogload, react_reward, adaptive_level_score, reaction_prompt_millis)

require(lme4)

# First, cognitive load and primary task performance. 

lmm_cog_perf <- lmer(adaptive_level_score ~ cogload + (1|subject_number) + (1|cogload:subject_number), data=df_cog)

summ(lmm_cog_perf, confint=TRUE)

# Now, cognitive load and STRT

lmm_cog_react <- lmer(reaction_prompt_millis ~ cogload + (1|subject_number) + (1|cogload:subject_number), data=df_cog)

summ(lmm_cog_react, confint=TRUE)

# Let's add reward to the STRT model

lmm_cog_rw_react <- lmer(reaction_prompt_millis ~ cogload*react_reward + (1|subject_number) + (1|cogload:subject_number) + (1|react_reward:subject_number), data=df_cog, control=lmerControl(optimizer="nloptwrap", calc.derivs = FALSE))

summ(lmm_cog_rw_react, confint=TRUE)

```

# Perceptual Load

```{r}

# Removing the perceptual load condition so we are just comparing to the control
df_perc <- df %>% filter(conditionstep!=3) %>% select(subject_number, percload, react_reward, adaptive_level_score, reaction_prompt_millis)

# Perceptual load and primary task performance. 

lmm_perc_perf <- lmer(adaptive_level_score ~ percload + (1|subject_number) + (1|percload:subject_number), data=df_perc)

summ(lmm_perc_perf, confint=TRUE)

# Perceptual load and STRT

lmm_perc_react <- lmer(reaction_prompt_millis ~ percload + (1|subject_number) + (1|percload:subject_number), data=df_perc)

summ(lmm_perc_react, confint=TRUE)

# Let's add reward to the STRT model

lmm_perc_rw_react <- lmer(reaction_prompt_millis ~ percload*react_reward + (1|subject_number) + (1|percload:subject_number) + (1|react_reward:subject_number), data=df_perc, control=lmerControl(optimizer="nloptwrap", calc.derivs = FALSE))

summ(lmm_perc_rw_react, confint=TRUE)

detach(package:lme4)
```

Let's do some an ANOVAs just to be sure nothing is screwy with our models. First, let's glom everything together within subjects, conditions, and reward.

```{r}
df_grouped <- df %>% 
  group_by(subject_number, cogload, percload, react_reward) %>%
  summarize(meanreact = mean(reaction_prompt_millis, na.rm=TRUE), 
            meanperf = mean(adaptive_level_score, na.rm=TRUE))
```

Now let's do the ANOVAs

```{r}

df_cog_grouped <- filter(df_grouped, percload=='low')

require(ez)

# performance ~ cogload
ezANOVA(data=df_cog_grouped,
        dv=meanperf,
        wid=.(subject_number),
        within=.(cogload),
        type = 3, detailed = TRUE)

# reaction time ~ cogload * reward
ezANOVA(data=df_cog_grouped, 
        dv=meanreact,
        wid=.(subject_number),
        within=.(cogload, react_reward),
        type = 3, detailed = TRUE)

df_perc_grouped <- filter(df_grouped, cogload=='low')

# performance ~ percload
ezANOVA(data=df_perc_grouped,
        dv=meanperf,
        wid=.(subject_number),
        within=.(percload),
        type = 3, detailed = TRUE)

# reaction time ~ percload * reward
ezANOVA(data=df_perc_grouped, 
        dv=meanreact,
        wid=.(subject_number),
        within=.(percload, react_reward),
        type = 3, detailed = TRUE)

```

# Plots
Let's do some plots that will look nice for the ICA presentation. First let's do the effects of cognitive and perceptual load on primary task performance. 

```{r}

# Cognitive Load

plt_data <- reactdata_clean %>% 
  filter(conditionstep != 2) %>%
  mutate(cogload= case_when(cogload == 1 ~ "low", 
                            cogload == 2 ~ "high", 
                            TRUE ~ NA_character_)) %>%
  group_by(subject_number, cogload) %>% 
  summarize(meanperf = mean(adaptive_level_score, na.rm=TRUE)) %>%
  group_by(cogload) %>%
  summarize(seperf = plotrix::std.error(meanperf, na.rm=TRUE), meanperf = mean(meanperf))

plt1 <- ggplot(data = plt_data, aes(x = as.factor(cogload), y = meanperf, fill = as.factor(cogload))) + 
  geom_bar(stat ="summary", fun.y='mean', position='dodge', show.legend = FALSE, width = 0.6) + 
  geom_errorbar(aes(x=as.factor(cogload), ymin=meanperf-seperf, ymax=meanperf+seperf), width = 0.1) +
  scale_x_discrete(limits = c("low", "high")) +
  theme(plot.margin = unit(c(6, 12, 6, 6), "pt")) +
  scale_fill_few(name = "Cognitive Load", labels = c("High", "Low")) +
  labs(x = "Cognitive Load", y = "Primary Task Performance")

plt_data <- reactdata_clean %>% 
  filter(conditionstep != 3) %>%
  mutate(percload= case_when(percload == 1 ~ "low", 
                            percload == 2 ~ "high", 
                            TRUE ~ NA_character_)) %>%
  group_by(subject_number, percload) %>% 
  summarize(meanperf = mean(adaptive_level_score, na.rm=TRUE)) %>%
  group_by(percload) %>%
  summarize(seperf = plotrix::std.error(meanperf, na.rm=TRUE), meanperf = mean(meanperf))

plt2 <- ggplot(data = plt_data, aes(x = as.factor(percload), y = meanperf, fill = as.factor(percload))) + 
  geom_bar(stat ="summary", fun.y='mean', position='dodge', show.legend = FALSE, width = 0.6) + 
  geom_errorbar(aes(x=as.factor(percload), ymin=meanperf-seperf, ymax=meanperf+seperf), width = 0.1) +
  scale_x_discrete(limits = c("low", "high")) +
  theme(plot.margin = unit(c(6, 12, 6, 6), "pt")) +
  scale_fill_few(name = "Perceptual Load", labels = c("High", "Low")) +
  labs(x = "Perceptual Load", y = "Primary Task Performance")

gridExtra::grid.arrange(plt1, plt2, ncol = 2)

```


```{r}
library(ggthemes)
library(ggplot2); theme_set(theme_few())

plt_data <- reactdata_clean %>% 
  group_by(subject_number, react_reward) %>% 
  summarize(meanRT = mean(reaction_prompt_millis)) %>%
  group_by(react_reward) %>%
  summarize(sert = plotrix::std.error(meanRT, na.rm=TRUE), meanRT = mean(meanRT))

plt1 <- ggplot(data = plt_data, aes(x = as.factor(react_reward), y = meanRT, fill = as.factor(react_reward))) + 
  geom_bar(stat ="summary", fun.y='mean', position='dodge', show.legend = FALSE, width = 0.6) + 
  geom_errorbar(aes(x=as.factor(react_reward), ymin=meanRT-sert, ymax=meanRT+sert), width = 0.1) +
  ylim(0,1400) +
  scale_x_discrete(limits = c("low", "high")) +
  theme(plot.margin = unit(c(6, 12, 6, 6), "pt")) +
  scale_fill_few(name = "Reward", labels = c("High", "Low")) +
  labs(x = "Reward", y = "Secondary Task Reaction Time")

plt_data <- reactdata_clean %>% 
  filter(conditionstep != 2) %>%
  mutate(cogload= case_when(cogload == 1 ~ "low", 
                            cogload == 2 ~ "high", 
                            TRUE ~ NA_character_)) %>%
  group_by(subject_number, cogload) %>% 
  summarize(meanRT = mean(reaction_prompt_millis)) %>%
  group_by(cogload) %>%
  summarize(sert = plotrix::std.error(meanRT, na.rm=TRUE), meanRT = mean(meanRT))

plt2 <- ggplot(data = plt_data, aes(x = as.factor(cogload), y = meanRT, fill = as.factor(cogload))) + 
  geom_bar(stat ="summary", fun.y='mean', position='dodge', show.legend = FALSE, width = 0.6) + 
  geom_errorbar(aes(x=as.factor(cogload), ymin=meanRT-sert, ymax=meanRT+sert), width = 0.1) +
  ylim(0,1400) +
  scale_fill_few(name = "Cognitive Load", labels = c("Low", "High")) +
  scale_x_discrete(limits = c("low", "high")) +
  theme(plot.margin = unit(c(6, 12, 6, 6), "pt")) +
  labs(x = "Cognitive Load", y = "Secondary Task Reaction Time")

plt_data <- reactdata_clean %>% 
  filter(conditionstep != 3) %>%
  mutate(percload= case_when(percload == 1 ~ "low",
                             percload == 2 ~ "high",
                             TRUE ~ NA_character_)) %>%
  group_by(subject_number, percload) %>% 
  summarize(meanRT = mean(reaction_prompt_millis)) %>%
  group_by(percload) %>%
  summarize(sert = plotrix::std.error(meanRT, na.rm=TRUE), meanRT = mean(meanRT))

plt3 <- ggplot(data = plt_data, aes(x = as.factor(percload), y = meanRT, fill = as.factor(percload))) + 
  geom_bar(stat ="summary", fun.y='mean', position='dodge', show.legend = FALSE, width = 0.6) + 
  geom_errorbar(aes(x=as.factor(percload), ymin=meanRT-sert, ymax=meanRT+sert), width = 0.1) +
  ylim(0,1400) +
  scale_fill_few(name = "Perceptual Load", labels = c("Low", "High")) +
  scale_x_discrete(limits = c("low", "high")) +
  theme(plot.margin = unit(c(6, 6, 6, 6), "pt")) +
  labs(x = "Perceptual Load", y = "Secondary Task Reaction Time")

gridExtra::grid.arrange(plt1, plt2, plt3, ncol =3)

```

Now for the interaction effects

```{r}
plt_data <- reactdata_clean %>% 
  filter(conditionstep != 2) %>%
  mutate(cogload= case_when(cogload == 1 ~ "low", 
                            cogload == 2 ~ "high", 
                            TRUE ~ NA_character_)) %>%
  group_by(subject_number, cogload, react_reward) %>% 
  summarize(meanRT = mean(reaction_prompt_millis)) %>%
  group_by(cogload, react_reward) %>%
  summarize(sert = plotrix::std.error(meanRT, na.rm=TRUE), meanRT = mean(meanRT))

ggplot(data = plt_data, aes(x = as.factor(cogload), y = meanRT, color = as.factor(react_reward), group = as.factor(react_reward))) + 
  geom_point() +
  geom_line() +
  geom_errorbar(aes(x=as.factor(cogload), ymin=meanRT-sert, ymax=meanRT+sert), width = 0.05) +
  scale_x_discrete(limits = c("low", "high")) +
  theme(plot.margin = unit(c(6, 12, 6, 6), "pt")) +
  scale_color_few(name = "Reward", labels = c("High", "Low")) +
  labs(x = "Cognitive Load", y = "Secondary Task Reaction Time")

plt_data <- reactdata_clean %>% 
  filter(conditionstep != 2) %>%
  mutate(cogload= case_when(cogload == 1 ~ "low", 
                            cogload == 2 ~ "high", 
                            TRUE ~ NA_character_)) %>%
  group_by(subject_number, cogload, react_reward) %>% 
  summarize(meanRT = mean(reaction_prompt_millis))

ggplot(plt_data, aes(x = meanRT, y = cogload, fill = react_reward, color = react_reward)) + ggridges::geom_density_ridges(jittered_points = TRUE, position = "raincloud", alpha = 0.8, scale = 0.9) + 
  scale_x_continuous(breaks=seq(0, 2500, 500)) +
  scale_fill_few(name = "Reward", labels = c("High", "Low")) + 
  scale_color_few(name = "Reward", labels = c("High", "Low")) + 
  labs(x = "Secondary Task Reaction Time", y = "Cognitive Load")
```


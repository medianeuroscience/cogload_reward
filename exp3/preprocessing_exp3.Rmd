---
title: "Preprocessing - Experiment 3"
output: html_document
  chunk_output_type: console
---

This notebook contains preprocessing steps necessary to get the data from experiment 3 in the paper "Of Primary Importance? Motivation Drives Resource Allocation Across Concurrent Tasks During Multimedia Processing" into the form used in the final analyses.

# Setup
Loading the packages that we will need.

```{r setup, include=FALSE}
library(tidyverse)
```

Getting the data from the scattered `.csv` files and pulling them together into an easier to use file.  

```{r, message = FALSE, warnings= FALSE}
# Make sure to set this correctly based on where you stored the data
setwd("~/projects/inprogress/cogperc/cogperc_4/analysis")
react_files = list.files(path ="data/reactlogs", pattern="*_reactlog.csv", full.names = TRUE)
log_files = list.files(path = "data/logs", pattern = "*.log.csv", full.names = TRUE)
reactdata = map_dfr(react_files, read_csv, col_types = "d-ddddcdcddccccdlc")

logdata = map_dfr(log_files, read_csv, col_types = "f-ddddcdcddfdddfdddfddd---------------------------------------------")
 
surveydata = read_csv("data/surveydata.csv")

```

# Preprocessing Log Data

Downsampling the `logdata` file so it's not such a behemoth. Downsampling to ~10Hz since there's no need for the ~60Hz resolution with the analyses that we will be doing.

```{r}
logdata_downsampled <- logdata %>% filter(total_millis %% 96 < 16)

# Getting rid of everything but the gameplay screen.

logdata_filt <- logdata_downsampled %>% filter(top_screen == "gameplay-adaptive") %>% 
  rename(sub_id = "subject_number") %>%
  mutate(sub_id = as.numeric(sub_id))

```

Now I'm going to compute the performance variable. I'm going to create a variable that counts the number of crystals collected and a variable that counts how often the person "dies" (runs their ship into an asteroid). I'll also create a variable that marks every thirty second chunk of gameplay.

```{r}

logdata_filt <- logdata_filt %>% group_by(sub_id, step_number) %>%
  mutate(target_acq = case_when(targets_collected - lag(targets_collected) != 0 ~ 1, 
                                TRUE ~ 0),
         dead = case_when(adaptive_level_score - lag(adaptive_level_score) == -1 ~ 1, 
                                TRUE ~ 0),
         thirtysec = step_millis %/% 30000)

```

Now I need to actually calculate the performance variable. I'll divide the number of crystals collected within each 30 second chunk by the number of times that the person died within that given chunk. This gives us a nice (semi-) normally distributed variable that stays more or less flat across time. 

```{r}
logdata_filt <- logdata_filt %>% 
  group_by(sub_id, step_number, thirtysec) %>% 
  summarize(perf = sum(target_acq)/(1+sum(dead))) %>% 
  filter(perf != 0)
```


# Preprocessing Reaction Prompt Data

The first thing that I need to do with the reaction time data is to create the variables that denote the cognitive load and perceptual load conditions. I'm not going to be using perceptual load in this experiment, but I'll go ahead and get it annotated.

```{r}

reactdata <- reactdata %>% rename(sub_id = "subject_number")
reactdata$sub_id <- as.numeric(as.character(reactdata$sub_id))

reactdata <- mutate(reactdata,
       condition = ifelse(sub_id %% 2 == 0, 2, 1),
       percload = ifelse(condition == 1 & step_number %in% c(8,10,15,18), 1,
                         ifelse(condition == 1 & step_number %in% c(13,20), 2,
                         ifelse(condition == 2 & step_number %in% c(7,10,15,17), 1,
                         ifelse(condition == 2 & step_number %in% c(12,20), 2, 0)))),
       cogload = ifelse(condition == 1 & step_number %in% c(8,13,15,20), 1,
                         ifelse(condition == 1 & step_number %in% c(10,18), 2,
                         ifelse(condition == 2 & step_number %in% c(7,12,15,20), 1,
                         ifelse(condition == 2 & step_number %in% c(10,17), 2, 0)))))

#Creates each of the two within subjects conditions and the control control  = 1, percload = 2, cogload = 3
reactdata <- mutate(reactdata,
                    conditionstep = ifelse(percload == 1 & cogload == 1, 1, 
                                  ifelse(percload == 2 & cogload == 1, 2,
                                    ifelse(percload == 1 & cogload == 2, 3, 0))))

# This gets rid of the practice condition.

reactdata <-filter(reactdata, conditionstep!= 0 & !is.na(adaptive_level_score))
```

Now I've got to create the reward conditions

```{r}
reactdata <- mutate(reactdata,
       reward = ifelse(condition == 1 & step_number %in% c(10,15,20), 1,
                         ifelse(condition == 1 & step_number %in% c(8,13,18), 2,
                         ifelse(condition == 2 & step_number %in% c(7,12,17), 1,
                         ifelse(condition == 2 & step_number %in% c(10,15,20), 2, 0)))))
```


## Data filtering

Since Asteroid Impact will miss probes when they start to overlap with one another, I need to upsample some of the data from the participants that missed a lot of the probes. I know that all of the differences should just be more probes that are missed, so I'll just pad the dataframes of each of the subjects with missed RT trials.  

```{r}

my_fun <- function(x,y) sample_n(y, size = x, replace = TRUE)

reactdata_pad <- reactdata %>% 
  group_by(sub_id, conditionstep) %>% 
  mutate(reaction_prompt_millis = case_when(reaction_prompt_passed == TRUE ~ reaction_prompt_millis,
                                            reaction_prompt_passed == FALSE ~ 2000)) %>%
  nest() %>%
  mutate(n = map(data, nrow)) %>%
  unnest(n) %>%
  mutate(n_short = 285-n,
         missed = map(data, filter, reaction_prompt_millis >= 2000),
         fill = map2(n_short, missed, my_fun),
         n_test = map(fill, nrow),
         full_df = map2(data, fill, rbind),
         n_full = map(full_df, nrow)) %>% 
  unnest(full_df) %>%
  select(-c(data, missed, fill, n_short, n_test, n_full))

```

Next, let's filter out the outliers. Ratcliff (1993) recommends using either the harmonic mean, inverse, or a standard deviation cutoff (+ or - 3 standard deviations from the mean). As our reaction times are naturally capped at 10sec by the software, we shouldn't need to do too much trimming. As the high tail of the distribution is important for the model, we don't want to use a method that will artificially compress the distribution to make it more normal looking. Because of these considerations I'm going to elect for a method that does not modify the actual distributions. We'll just trim all values that are outside of the +- 3sd range within subjects and conditions.

```{r}

reactdata_filt <- reactdata_filt %>% 
  group_by(cogload, reward) %>% 
  mutate(meanreact = mean(reaction_prompt_millis), 
         sdreact = sd(reaction_prompt_millis), 
         react_cutoff = (mean(reaction_prompt_millis) + 3 * sd(reaction_prompt_millis))) %>%
  filter(!(abs(reaction_prompt_millis - median(reaction_prompt_millis)) > 3*sd(reaction_prompt_millis))) %>% 
  filter(reaction_prompt_millis > 100) %>%
  ungroup()

```

# Preprocessing Survey Data

```{r}
vars <- c(sub_id = "Q1", age = "Q7", sex = "Q9", ethnicity = "Q11", vision = "Q56", handedness = "Q57", vg_skill = "Q70_1")

surveydata <- surveydata %>% rename(!!vars)

surveydata_filt <- surveydata %>% select(sub_id, age, sex, ethnicity, vision, handedness, vg_skill)
```

# Merging into one DF

```{r}
reactdata_filt <- reactdata_filt %>% 
  mutate(thirtysec = step_millis %/% 30000)

reactdata_plus_logs <- left_join(reactdata_filt, logdata_filt, by = c("sub_id", "step_number", "thirtysec"))

# Replacing missing performance data with the median performance for that condition

reactdata_plus_logs <- reactdata_plus_logs %>% 
  group_by(sub_id, cogload, reward) %>% 
  mutate(perf = case_when(is.na(perf) ~ mean(perf, na.rm=TRUE),
                          TRUE ~ perf))

fulldata <- left_join(reactdata_plus_logs, surveydata_filt, by = "sub_id")
```

# Some final filtering

Let's get rid of the subjects for which we don't have surveys, and also check to make sure we have the same number of observations per subject after merging.

```{r}
fulldata <- fulldata %>% filter(!is.na(sex)) %>% filter(sex != "")

View(fulldata %>% group_by(sub_id) %>% summarize(n = n()))

```

Getting rid of outliers

```{r}
# First, we'll get the mean of responses per subject and the mean performance per subject

outs <- fulldata %>% 
  group_by(sub_id, conditionstep) %>% 
  summarize(meanreact = mean(reaction_prompt_millis, na.rm=TRUE), 
            meanperf = mean(perf, na.rm=TRUE)) %>%
  ungroup()

# Now we'll get the z-scores of the mean reaction times so that we can filter those > 3

outs_react <- outs %>%
  mutate(react_z = (meanreact - mean(meanreact, na.rm = TRUE)) / sd(meanreact)) %>%
  filter(react_z > 3)

# Looks like subjects 1038, 1052, and 1070 missed a disproportionate number of STRTs

outs_perf <- outs %>%
  mutate(perf_z = (meanperf - mean(meanperf, na.rm = TRUE)) / sd(meanperf)) %>%
  filter(perf_z > 3)

# Looks like no outliers for performance

```

Looks like subjects 1013, 1021, 1029, 1061, & 1071 never responded to the STRT probes. Subjects 1012 & 1062 didn't collect hardly any crystals. Subject 1023 has inhumanly fast RTS, indicating that they were just pressing the spacebar over and over. We will go ahead and toss them.  

```{r}
fulldata <- filter(fulldata, !(sub_id %in% c(1012, 1013, 1021, 1023, 1029, 1045, 1059, 1061, 1062, 1071)))
```

Looks good to go.

```{r}
write_csv(fulldata, path = "fulldata_exp3.csv")
```

